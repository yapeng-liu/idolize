{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n    raise exc from None\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n    response = await connection.handle_async_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n    return await self._connection.handle_async_request(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 143, in handle_async_request\n    raise exc\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 113, in handle_async_request\n    ) = await self._receive_response_headers(**kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 186, in _receive_response_headers\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 224, in _receive_event\n    data = await self._network_stream.read(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 32, in read\n    with map_exceptions(exc_map):\n  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1558, in _request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1661, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 372, in handle_async_request\n    with map_httpcore_exceptions():\n  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1295, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1577, in _request\n    raise APITimeoutError(request=request) from err\nopenai.APITimeoutError: Request timed out.\n", "source": "Request timed out.", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n    raise exc from None\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n    response = await connection.handle_async_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n    return await self._connection.handle_async_request(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 143, in handle_async_request\n    raise exc\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 113, in handle_async_request\n    ) = await self._receive_response_headers(**kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 186, in _receive_response_headers\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 224, in _receive_event\n    data = await self._network_stream.read(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 32, in read\n    with map_exceptions(exc_map):\n  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1558, in _request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1661, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 372, in handle_async_request\n    with map_httpcore_exceptions():\n  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1295, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1577, in _request\n    raise APITimeoutError(request=request) from err\nopenai.APITimeoutError: Request timed out.\n", "source": "Request timed out.", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Error Invoking LLM", "stack": "Traceback (most recent call last):\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 69, in map_httpcore_exceptions\n    yield\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n    raise exc from None\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n    response = await connection.handle_async_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n    return await self._connection.handle_async_request(request)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 143, in handle_async_request\n    raise exc\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 113, in handle_async_request\n    ) = await self._receive_response_headers(**kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 186, in _receive_response_headers\n    event = await self._receive_event(timeout=timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_async/http11.py\", line 224, in _receive_event\n    data = await self._network_stream.read(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 32, in read\n    with map_exceptions(exc_map):\n  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\nhttpcore.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1558, in _request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1661, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 372, in handle_async_request\n    with map_httpcore_exceptions():\n  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/home/robo/.local/lib/python3.11/site-packages/httpx/_transports/default.py\", line 86, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\nhttpx.ReadTimeout\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 1295, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/openai/_base_client.py\", line 1577, in _request\n    raise APITimeoutError(request=request) from err\nopenai.APITimeoutError: Request timed out.\n", "source": "Request timed out.", "details": {"input": "MANY entities were missed in the last extraction.  Add them below using the same format:\n"}}
{"type": "error", "data": "Community Report Extraction Error", "stack": "Traceback (most recent call last):\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py\", line 58, in __call__\n    await self._llm(\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/home/robo/.local/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n                                     ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n           ^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/base/base_llm.py\", line 48, in __call__\n    return await self._invoke_json(input, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 82, in _invoke_json\n    result = await generate()\n             ^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 76, in generate\n    else await self._manual_json(input, **{**kwargs, \"name\": call_name})\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/openai/openai_chat_llm.py\", line 133, in _manual_json\n    json = try_parse_json_object(output)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/robo/.local/lib/python3.11/site-packages/graphrag/llm/openai/utils.py\", line 93, in try_parse_json_object\n    result = json.loads(input)\n             ^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/json/__init__.py\", line 346, in loads\n    return _default_decoder.decode(s)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/json/decoder.py\", line 337, in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/json/decoder.py\", line 355, in raw_decode\n    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\njson.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n", "source": "Expecting value: line 1 column 1 (char 0)", "details": null}
